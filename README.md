# SRIDHAR ERUKULLA                                                                                                Mobile  +91 9949197710

![Banner](https://github.com/Sridhar-Erukulla/Sridhar-Erukulla/blob/main/data-engineering-dl-2020-1024x401-1.png?raw=true)
<!-- Add your image with specified width and height -->
<img src="https://github.com/Sridhar-Erukulla/Sridhar-Erukulla/blob/main/WhatsApp%20Image%202023-11-20%20at%2011.38.49%20PM.jpeg?raw=true" alt="My Profile Picture" width="300" height="300">

<!-- Add other content below if needed -->




## Data Engineer
## Database Expert

[![LinkedIn](https://img.shields.io/badge/LinkedIn-YourLinkedInProfile-blue)](https://www.linkedin.com/in/your-linkedin-profile/)
[![GitHub](https://img.shields.io/badge/GitHub-YourGitHubProfile-green)](https://github.com/your-github-profile)
[![Portfolio](https://img.shields.io/badge/Portfolio-YourPortfolioWebsite-orange)](https://www.your-portfolio-website.com/)

---

## Overview

- I am a skilled and passionate data engineer with a strong background in designing, building, and maintaining scalable data infrastructure. My expertise lies in data modeling, ETL (Extract, Transform, Load) processes, and optimizing data pipelines for performance and reliability.
- 	Good Exposure to Financial and investment Banking domain knowledge.
- 	Regulatory report testing and SWIFT message validation testing.
- 	Efficient Teradata development skills in Teradata SQL Objects, Creating Tables, Stored Procedures, Functions, Views, Indexing, Performance Tuning.
- 	Implement data validation/verification strategies, plans and use cases for various Data Warehousing & Data Analysis solutions.
- 	Experience in writing complex SQL statements to validate data and ETL code based on the data mapping & requirements and perform extensive data analysis to identify the defects.
- 	Perform detailed Data Analysis, Data Profiling and Data Integrity check using SQL, Shell scripts or any other tools.
- 	Strong analytical and trouble shooting skills in resolving complex technical problems and PROD issues.
- 	Performance testing for Database Benchmarking.
- 	Good knowledge in Agile and Project management activities.
- 	Data Modeling  logical and physical data models, to support Business requirements.
- 	Good Knowledge on  DevOps processes. Knowledge on CI/CD Tools like Jenkins, Git, Ansible.
- 	Participate in Business walkthrough calls  to establish requirements to achieve business objectives through Data. Decompose the business requirements into one or more reusable DWH/ETL products.
- 	Translate business requirements into Dataware housing /ETL Solutions
- 	Debugging, monitoring and troubleshooting existing Data Warehouse housing solutions 
- 	Excellent working knowledge of large data manipulation and data mining using complex SQL.
- 	Performed end-to end Integration testing cycles for various projects.
- 	Writing the Test plan Documents and Unit Test cases for functional testing and regression tests.
- 	Worked closely with software developers/project owners to develop and execute thorough test suites in all phases of the software development cycle.
- 	Develop Test strategy, test plan/design, execute test cases and defect management for the EDW/DWH systems.
- 	Teradata database Internals and good understanding of the explain text.
- 	Experienced in Teradata end to end DBA and development activities: Database Administration, Tuning, System maintenance, objects, space & privileges maintenance, Crash dumps analysis
- 	Teradata System Health Reporting using DBQL Data, RSS and PDCR.
- 	Complete TASM expertise in analyzing the existing workloads using Teradata workload analyzer, designing, adjusting & monitoring the workloads using Workload Designer and Workload Monitor port lets.
-  Excellent communication and presentation skills, a strong commitment towards Customer Satisfaction. Ensure effective communication of user requirements.

---

## Skills

- **Programming Languages:** Python, SQL
- **Big Data Technologies:** Apache Spark, Hadoop
- **Databases:** PostgreSQL, MySQL, MongoDB
- **ETL Tools:** Apache NiFi, Apache Airflow
- **Data Warehousing:** Amazon Redshift, Google BigQuery
- **Version Control:** Git
- **Infrastructure as Code:** Terraform
- **Containerization:** Docker, Kubernetes
- **Workflow Orchestration:** Apache Airflow

---

## Professional Experience

### [Current/Last Company Name] - [Location] (Month/Year - Present/End Date)

#### Data Engineer

- Collaborated with cross-functional teams to understand data requirements and design scalable data solutions.
- Implemented ETL processes to extract, transform, and load data from various sources into a centralized data warehouse.
- Optimized data pipelines for performance and reliability, reducing processing times by X%.

### [Previous Company Name] - [Location] (Month/Year - Month/Year)

#### Junior Data Engineer

- Assisted in the development of data pipelines, ensuring the timely and accurate flow of data between systems.
- Conducted data profiling and quality assessments to identify and address data issues.
- Contributed to the maintenance and enhancement of existing data infrastructure.

---

## Education

### [University Name] - [Degree Earned] (Month/Year - Month/Year)

- Relevant coursework: [List relevant courses related to data engineering]

---

## Projects

### [Project Name]

- Description: Brief description of the project, including your role and contributions.
- Technologies Used: List the technologies and tools used in the project.
- Link to GitHub Repo or Demo: [GitHub Repo or Demo Link]

### [Project Name]

- Description: Brief description of the project, including your role and contributions.
- Technologies Used: List the technologies and tools used in the project.
- Link to GitHub Repo or Demo: [GitHub Repo or Demo Link]

---

## Certifications

- [Certification Name] - [Issuing Organization] (Month/Year)

---

## Contact

- Email: sridhar.erukulla@gmail.com
- Phone: 9949197710
- Location: Hyderabad, telangana-500017.

---

## Additional Information

- Open to new opportunities.
- Available for relocation.

---

Feel free to reach out if you have any questions or if you are interested in collaborating on exciting data engineering projects!

